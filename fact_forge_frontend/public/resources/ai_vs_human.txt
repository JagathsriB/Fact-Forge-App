# How Our AI vs Human Text Detection System Works

This system combines **machine learning**, **API-based analysis**, and **heuristic intelligence** to determine whether a piece of text was written by a **human** or generated by **AI**.  
It balances precision, interpretability, and reliability through multiple layers of verification.

---

## 1. Local Text Classification Model — *The Core Analyzer*

At the heart of the system is a **Logistic Regression model** trained to distinguish between human and AI-written text.

### Training Data
The model learns from a labeled dataset (`aivshuman.csv`) containing two types of samples:
- `0` → Human-written text  
- `1` → AI-generated text  

Each row includes a `text` and `generated` field, ensuring clear supervision during training.

### Feature Extraction
Text is transformed using **TF-IDF (Term Frequency–Inverse Document Frequency)** with a limit of 5,000 features.  
This technique highlights distinctive linguistic patterns — frequency, tone, and phrasing — that separate human from machine authorship.

### Model Learning
A **Logistic Regression** classifier is trained for up to 500 iterations to identify the boundary between AI-like and human-like writing styles.

### Outputs
- **Prediction:** `AI` or `Human`  
- **Confidence:** Probability (in %) that the text is AI-generated  

### Model Persistence
Both the **trained model** and **vectorizer** are saved locally as:
- `model.pkl`
- `vectorizer.pkl`

This allows fast, offline reuse and deployment.

---

## 2. External Verification — *The Expert Panel*

To boost accuracy and trustworthiness, the system cross-checks each prediction using two specialized external APIs and one grammar engine.

### Hugging Face AI Detector
Powered by **`desklib/ai-text-detector-v1.01`**, this model analyzes text for AI-like structure and coherence.  
It returns a **score (0.0–1.0)** representing the likelihood of AI authorship.

### Sapling AI Detector
Utilizes **Sapling’s AI Detection API** to measure the degree of automation in the writing style, generating another **AI probability score (0.0–1.0)**.

### Sapling Grammar Checker
A secondary Sapling API evaluates the text’s **grammatical quality**, identifying:
- Number of detected grammar edits  
- A computed **grammar score (0–100)**  

This score helps differentiate polished AI text from natural human writing, which often contains minor inconsistencies.

---

## 3. Input Method Analysis — *Heuristic Behavior Check*

The system observes **how** the text was entered to infer intent or authenticity.

- **Typed:** If the user takes longer to input text, suggesting manual typing.  
- **Pasted:** If long text (>50 characters) is entered in under 0.2 seconds — typical of copied AI outputs.  

This adds behavioral context to linguistic predictions.

---

## 4. Decision Engine — *Voting-Based Verdict*

After collecting predictions from all sources, the system applies a **majority-vote ensemble** to decide the final label.

### Voting Sources
1. Local Logistic Regression model  
2. Hugging Face AI Detector  
3. Sapling AI Detector  

### Final Verdict
- **AI** → If at least two sources classify the text as AI-generated  
- **Human** → Otherwise  

Each result includes:
- Final classification (`AI` or `Human`)
- Input method (typed/pasted)
- Local model confidence
- API scores
- Grammar evaluation
- Voting breakdown

---

## 5. Interactive User Interface — *Live Detection Mode*

The system runs interactively in the command line.

### Workflow:
1. User enters text manually or pastes it.  
2. System measures typing duration.  
3. All detectors analyze the input simultaneously.  
4. A structured JSON report is displayed.

